
# Very promising. Though keeps asking without "user_question". 
# The code is then written into the console instead if the file. 
# As a result, the files were almost empty.

# The model has an engineered context size max context size of 128k. However, it is not sure how well it will perform on the large end.

# With context size 32k, the model uses 36GB of VRAM
#FROM tom_himanen/deepseek-r1-roo-cline-tools:32b
#PARAMETER num_ctx 32768

# 33GB VRAM at 57 context size.
FROM tom_himanen/deepseek-r1-roo-cline-tools:14b
PARAMETER num_ctx 57344


#FROM tom_himanen/deepseek-r1-roo-cline-tools:8b

#PARAMETER num_ctx 65536
#PARAMETER num_ctx 100000
#PARAMETER num_ctx 131072
