# FROM starcoder2:15b-instruct - this model is the same as 15b-instruct-q4_0
FROM starcoder2:15b-instruct-v0.1-q5_K_M

# llm_load_print_meta: n_ctx_train      = 16384
# llm_load_print_meta: rope type        = 2
# llm_load_print_meta: rope scaling     = linear
# llm_load_print_meta: freq_base_train  = 100000.0
# llm_load_print_meta: freq_scale_train = 1
# 16k context, but supports rope scaling

# 26GB VRAM, at 32k context size
# 33GB VRAM, at 48k context size

# careful! Trained context overflow!

#PARAMETER num_ctx 32768
PARAMETER num_ctx 49125
#PARAMETER num_ctx 57344
#PARAMETER num_ctx 65536
#PARAMETER num_ctx 100000
#PARAMETER num_ctx 131072
